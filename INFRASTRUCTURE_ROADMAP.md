# Yeti Infrastructure Roadmap: Research to Reality

## Phase 1: The Sovereign Research Lab (In-House)
**Hardware Focus**: NVIDIA RTX A6000 Ada (48GB VRAM)

| Objective | Technical Strategy | Outcome |
| :--- | :--- | :--- |
| **Model Excellence** | Run full or high-bit quantized models (up to 70B parameters). | Maximum intelligence for internal workflows and agent logic development. |
| **Fine-Tuning** | Local LoRA/QLoRA training on Digital Wallet's proprietary data. | Yeti becomes an expert in Japanese fintech and DW's internal processes. |
| **Privacy Sandbox** | 100% air-gapped development for sensitive R&D projects. | High-security environment that exceeds international compliance standards. |

## Phase 2: Public-Facing Utilities (Scalable Cloud)
**Hardware Focus**: Specialized AI Cloud (AWS g5/p4 instances, Lambda Labs, or RunPod)

| Objective | Technical Strategy | Outcome |
| :--- | :--- | :--- |
| **Global Reach** | Deployment via Kubernetes/Docker on cloud clusters. | Low-latency response for users globally, starting with Japan. |
| **Cost Efficiency** | Implementation of `vLLM` or `TGI` for high-throughput serving. | Ability to handle hundreds of concurrent users at a fraction of API costs. |
| **Hybrid Sync** | Lab-proven models are pushed to the cloud once validated. | Seamless transition from "Research Lab" to "Public Utility." |

---

## The "Sovereign Hybrid" Advantage
This dual-path approach solves the primary enterprise dilemma:

1.  **Innovation (Internal)**: You aren't restricted by OpenAI's rate limits or model updates. You own the laboratory.
2.  **Scalability (Public)**: You use the cloud only for its strength—distribution—while keeping the "Intellectual Property" (the model weights and logic) portable across any provider.

> [!IMPORTANT]
> By choosing the **A6000 Ada**, you aren't just buying hardware; you are establishing **Technological Freedom**. You could even run multiple "small" models (like several Mistral-Nemos) for different departments simultaneously on a single card.
